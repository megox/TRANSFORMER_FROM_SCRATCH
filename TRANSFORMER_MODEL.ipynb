{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORTS**"
      ],
      "metadata": {
        "id": "w5lTAyMO3DZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vk0U5qButED",
        "outputId": "1c5a11b1-960a-45e8-8856-5db27656387c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import math\n",
        "from collections import Counter\n",
        "import kagglehub\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, words\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DOWNLOADS**"
      ],
      "metadata": {
        "id": "ShNGLMTF2zHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('words')\n",
        "\n",
        "#--------glove EMPEDDINGS   100D , 300D ---------------------------------------\n",
        "# path = kagglehub.dataset_download(\"thanakomsn/glove6b300dtxt\")\n",
        "# print(\"Path to dataset files:\", path)\n",
        "\n",
        "path = kagglehub.dataset_download(\"danielwillgeorge/glove6b100dtxt\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "bNwfsU9M2ybA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD** **DATA**"
      ],
      "metadata": {
        "id": "VyhFtYYo2a1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgNj-X_YutAo"
      },
      "outputs": [],
      "source": [
        "data_path = \"train.csv\"\n",
        "data = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "Tf3jK8TL2mzT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJfO8IOCus-K"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()\n",
        "data = data[data['Discussion'].str.strip() != '']\n",
        "\n",
        "\n",
        "categoryMap = {\n",
        "    \"Politics\": 0,\n",
        "    \"Sports\": 1,\n",
        "    \"Media\": 2,\n",
        "    \"Market & Economy\": 3,\n",
        "    \"STEM\": 4\n",
        "}\n",
        "data['Category'] = data['Category'].map(categoryMap)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load the list of valid English words\n",
        "english_words = set(words.words())\n",
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "\n",
        "    # Replace newline characters with spaces\n",
        "    text = text.replace('\\\\n', ' ')\n",
        "\n",
        "    # Remove backslashes and other URL characters\n",
        "    text = re.sub(r'[\\\\?=&_\\-]', ' ', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APPLY PREPROSSESING ON DISCUSSION COLUMN**"
      ],
      "metadata": {
        "id": "odBzipRO31WF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns7C8_bAus70"
      },
      "outputs": [],
      "source": [
        "data['Discussion'] = data['Discussion'].apply(preprocess_text)\n",
        "data = data[data['Discussion'].str.strip() != '']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TOKENIZATION**"
      ],
      "metadata": {
        "id": "7OmQ1qbL4HyN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2isDKIgus5Q"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "max_length = 120  # Length to truncate or pad sequences\n",
        "\n",
        "# Tokenize text using BERT tokenizer\n",
        "def bert_tokenize(text, max_length):\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,  # Add [CLS] and [SEP]\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    return encoding['input_ids'].squeeze(0), encoding['attention_mask'].squeeze(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tokenize all discussions\n",
        "encoded_texts, attention_masks = [], []\n",
        "for text in data['Discussion']:\n",
        "    input_ids, attn_mask = bert_tokenize(text, max_length)\n",
        "    encoded_texts.append(input_ids)\n",
        "    attention_masks.append(attn_mask)\n",
        "\n",
        "# Convert labels to tensor\n",
        "labels = torch.tensor(data['Category'].tolist())\n",
        "\n",
        "# Train/Validation split\n",
        "train_size = int(0.8 * len(encoded_texts))\n",
        "train_encoded, train_masks = encoded_texts[:train_size], attention_masks[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "\n",
        "val_encoded, val_masks = encoded_texts[train_size:], attention_masks[train_size:]\n",
        "val_labels = labels[train_size:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EMBEDDING**"
      ],
      "metadata": {
        "id": "tVbP_eSX5FRC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w0w6Bwom-f2"
      },
      "outputs": [],
      "source": [
        "def load_glove_embeddings(glove_file_path, vocab, embed_dim=100):\n",
        "    embeddings = np.zeros((len(vocab), embed_dim))\n",
        "    # Load GloVe embeddings\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            if word in vocab:\n",
        "                embeddings[vocab[word]] = vector\n",
        "    return torch.tensor(embeddings, dtype=torch.float32)\n",
        "\n",
        "\n",
        "glove_file_path = '/root/.cache/kagglehub/datasets/danielwillgeorge/glove6b100dtxt/versions/1/glove.6B.100d.txt'\n",
        "vocab = tokenizer.get_vocab()\n",
        "embed_dim = 100\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, vocab, embed_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL**"
      ],
      "metadata": {
        "id": "dHuIQypl47pI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0xNJT1Eus0X"
      },
      "outputs": [],
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, encoded_texts, attention_masks, labels):\n",
        "        self.encoded_texts = encoded_texts\n",
        "        self.attention_masks = attention_masks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.encoded_texts[idx]\n",
        "        mask = self.attention_masks[idx]\n",
        "        y = self.labels[idx]\n",
        "        return x, mask, y\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = TextClassificationDataset(train_encoded, train_masks, train_labels)\n",
        "val_dataset = TextClassificationDataset(val_encoded, val_masks, val_labels)\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TKrYo6kusxx"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_dim, max_length=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_length, embed_dim)\n",
        "        position = torch.arange(0, max_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)  # (1, max_length, embed_dim)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, seq_length, embed_dim)\n",
        "        seq_length = x.size(1)\n",
        "        x = x + self.pe[:, :seq_length, :]\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert embed_dim % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        self.query_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_length, _ = x.size()\n",
        "\n",
        "        Q = self.query_proj(x)\n",
        "        K = self.key_proj(x)\n",
        "        V = self.value_proj(x)\n",
        "\n",
        "        # (batch_size, seq_length, num_heads, head_dim)\n",
        "        Q = Q.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1,2)\n",
        "        K = K.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1,2)\n",
        "        V = V.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1,2)\n",
        "\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        if mask is not None:\n",
        "            # mask: (batch_size, seq_length) -> we need (batch_size, 1, 1, seq_length)\n",
        "            # We'll create a broadcastable mask to apply to attn_scores\n",
        "            mask = mask.unsqueeze(1).unsqueeze(2)  # (batch_size, 1, 1, seq_length)\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context = torch.matmul(attn_weights, V)\n",
        "        context = context.transpose(1,2).contiguous().view(batch_size, seq_length, self.embed_dim)\n",
        "        out = self.out_proj(context)\n",
        "        return out\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, embed_dim, ff_dim, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(embed_dim, ff_dim)\n",
        "        self.fc2 = nn.Linear(ff_dim, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(embed_dim, num_heads, dropout)\n",
        "        self.ffn = PositionwiseFeedForward(embed_dim, ff_dim, dropout)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attn_out = self.self_attn(x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_out))\n",
        "\n",
        "        ffn_out = self.ffn(x)\n",
        "        x = self.norm2(x + self.dropout(ffn_out))\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, num_layers, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerEncoderLayer(embed_dim, num_heads, ff_dim, dropout) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return x\n",
        "\n",
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, glove_embeddings ,embed_dim=300, num_heads=8, num_layers=4, ff_dim=512, num_classes=5, max_length=120, dropout=0.1):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "\n",
        "        # GloVe embeddings as input to the embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.embedding.weight.data.copy_(glove_embeddings)  # Set GloVe weights\n",
        "        self.embedding.weight.requires_grad = False  # Optionally freeze the embedding layer\n",
        "        self.pos_encoding = PositionalEncoding(embed_dim, max_length=max_length)\n",
        "\n",
        "        self.encoder = TransformerEncoder(embed_dim, num_heads, ff_dim, num_layers, dropout)\n",
        "\n",
        "        self.fc = nn.Linear(embed_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = self.embedding(x)  # (batch_size, seq_length, embed_dim)\n",
        "        x = self.pos_encoding(x)\n",
        "\n",
        "        # Pass the mask to the encoder\n",
        "        x = self.encoder(x, mask=mask)  # (batch_size, seq_length, embed_dim)\n",
        "\n",
        "        # Use the [CLS] token representation\n",
        "        cls_token_repr = x[:, 0, :]  # (batch_size, embed_dim)\n",
        "\n",
        "        x = self.dropout(cls_token_repr)\n",
        "        logits = self.fc(x)  # (batch_size, num_classes)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training and Evaluation**"
      ],
      "metadata": {
        "id": "TWjxeISV5er8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgxgbFJUusvf",
        "outputId": "12c4f0fe-fc56-4cd7-fabf-bb41b9c36e6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Train Loss: 1.2174, Train Accuracy: 0.5055\n",
            "Validation Loss: 0.9446, Validation Accuracy: 0.6485\n",
            "--------------------------------------------------\n",
            "Epoch 2/10\n",
            "Train Loss: 0.9472, Train Accuracy: 0.6422\n",
            "Validation Loss: 0.8552, Validation Accuracy: 0.6705\n",
            "--------------------------------------------------\n",
            "Epoch 3/10\n",
            "Train Loss: 0.8993, Train Accuracy: 0.6607\n",
            "Validation Loss: 0.8324, Validation Accuracy: 0.6896\n",
            "--------------------------------------------------\n",
            "Epoch 4/10\n",
            "Train Loss: 0.8755, Train Accuracy: 0.6695\n",
            "Validation Loss: 0.8330, Validation Accuracy: 0.6818\n",
            "--------------------------------------------------\n",
            "Epoch 5/10\n",
            "Train Loss: 0.8573, Train Accuracy: 0.6735\n",
            "Validation Loss: 0.8535, Validation Accuracy: 0.6875\n",
            "--------------------------------------------------\n",
            "Epoch 6/10\n",
            "Train Loss: 0.8423, Train Accuracy: 0.6817\n",
            "Validation Loss: 0.8313, Validation Accuracy: 0.6885\n",
            "--------------------------------------------------\n",
            "Epoch 7/10\n",
            "Train Loss: 0.8301, Train Accuracy: 0.6851\n",
            "Validation Loss: 0.8106, Validation Accuracy: 0.6904\n",
            "--------------------------------------------------\n",
            "Epoch 8/10\n",
            "Train Loss: 0.8167, Train Accuracy: 0.6905\n",
            "Validation Loss: 0.8056, Validation Accuracy: 0.6957\n",
            "--------------------------------------------------\n",
            "Epoch 9/10\n",
            "Train Loss: 0.8082, Train Accuracy: 0.6935\n",
            "Validation Loss: 0.8049, Validation Accuracy: 0.7022\n",
            "--------------------------------------------------\n",
            "Epoch 10/10\n",
            "Train Loss: 0.7968, Train Accuracy: 0.7003\n",
            "Validation Loss: 0.8063, Validation Accuracy: 0.7028\n",
            "--------------------------------------------------\n",
            "Epoch 1/10\n",
            "Train Loss: 1.2339, Train Accuracy: 0.4938\n",
            "Validation Loss: 0.9396, Validation Accuracy: 0.6493\n",
            "--------------------------------------------------\n",
            "Epoch 2/10\n",
            "Train Loss: 0.9373, Train Accuracy: 0.6434\n",
            "Validation Loss: 0.8676, Validation Accuracy: 0.6687\n",
            "--------------------------------------------------\n",
            "Epoch 3/10\n",
            "Train Loss: 0.8868, Train Accuracy: 0.6624\n",
            "Validation Loss: 0.8455, Validation Accuracy: 0.6785\n",
            "--------------------------------------------------\n",
            "Epoch 4/10\n",
            "Train Loss: 0.8634, Train Accuracy: 0.6728\n",
            "Validation Loss: 0.8219, Validation Accuracy: 0.6918\n",
            "--------------------------------------------------\n",
            "Epoch 5/10\n",
            "Train Loss: 0.8436, Train Accuracy: 0.6767\n",
            "Validation Loss: 0.8214, Validation Accuracy: 0.6906\n",
            "--------------------------------------------------\n",
            "Epoch 6/10\n",
            "Train Loss: 0.8303, Train Accuracy: 0.6848\n",
            "Validation Loss: 0.8227, Validation Accuracy: 0.6875\n",
            "--------------------------------------------------\n",
            "Epoch 7/10\n",
            "Train Loss: 0.8151, Train Accuracy: 0.6913\n",
            "Validation Loss: 0.8065, Validation Accuracy: 0.6981\n",
            "--------------------------------------------------\n",
            "Epoch 8/10\n",
            "Train Loss: 0.8073, Train Accuracy: 0.6924\n",
            "Validation Loss: 0.8030, Validation Accuracy: 0.6963\n",
            "--------------------------------------------------\n",
            "Epoch 9/10\n",
            "Train Loss: 0.7993, Train Accuracy: 0.6976\n",
            "Validation Loss: 0.8097, Validation Accuracy: 0.6988\n",
            "--------------------------------------------------\n",
            "Epoch 10/10\n",
            "Train Loss: 0.7889, Train Accuracy: 0.7002\n",
            "Validation Loss: 0.8063, Validation Accuracy: 0.7030\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the TransformerClassifier\n",
        "model = TransformerClassifier(\n",
        "    vocab_size=tokenizer.vocab_size,  # Using BERT tokenizer's vocabulary size\n",
        "    glove_embeddings=glove_embeddings,  # Pass the GloVe embeddings\n",
        "    embed_dim=100,   # increased embedding dimension\n",
        "    num_heads = 4,     # more heads\n",
        "    num_layers= 2,    # more layers\n",
        "    ff_dim=512,      # bigger feed-forward\n",
        "    num_classes=5,\n",
        "    max_length=max_length,  # Ensure this matches the tokenizer's max_length\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.9)\n",
        "\n",
        "\n",
        "\n",
        "epochs = 10  # Number of epochs\n",
        "total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_train_loss = 0\n",
        "    total_val_loss = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    model.train()\n",
        "\n",
        "    # Training loop\n",
        "    for batch in train_loader:\n",
        "        x_batch, mask_batch, y_batch = batch  # Unpack the tuple\n",
        "        x_batch = x_batch.to(device)          # Move input IDs to the device\n",
        "        mask_batch = mask_batch.to(device)    # Move attention masks to the device\n",
        "        y_batch = y_batch.to(device)          # Move labels to the device\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x_batch, mask=mask_batch)  # Include attention mask\n",
        "        loss = criterion(logits, y_batch)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct_train += (preds == y_batch).sum().item()\n",
        "        total_train += y_batch.size(0)\n",
        "\n",
        "    train_loss = total_train_loss / total_steps\n",
        "    train_accuracy = correct_train / total_train\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            x_batch, mask_batch, y_batch = batch  # Unpack the tuple\n",
        "            x_batch = x_batch.to(device)\n",
        "            mask_batch = mask_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            logits = model(x_batch, mask=mask_batch)\n",
        "            loss = criterion(logits, y_batch)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct_val += (preds == y_batch).sum().item()\n",
        "            total_val += y_batch.size(0)\n",
        "\n",
        "    val_loss = total_val_loss / len(val_loader)\n",
        "    val_accuracy = correct_val / total_val\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw5CzcobB57h"
      },
      "source": [
        "# **Test** **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F4j3zzGBlan"
      },
      "outputs": [],
      "source": [
        "data_path = \"test.csv\"\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, encoded_texts, attention_masks):\n",
        "        self.encoded_texts = encoded_texts\n",
        "        self.attention_masks = attention_masks\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.encoded_texts[idx]\n",
        "        mask = self.attention_masks[idx]\n",
        "        return x, mask\n",
        "\n",
        "\n",
        "# Tokenize all discussions\n",
        "data['Discussion'] = data['Discussion'].apply(preprocess_text)\n",
        "\n",
        "encoded_texts, attention_masks = [], []\n",
        "for text in data['Discussion']:\n",
        "    input_ids, attn_mask = bert_tokenize(text, max_length)\n",
        "    encoded_texts.append(input_ids)\n",
        "    attention_masks.append(attn_mask)\n",
        "\n",
        "\n",
        "\n",
        "test_dataset = TestDataset(encoded_texts, attention_masks)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BUWmxnfRlQA"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    predictions = []  # Initialize predictions list inside the function\n",
        "\n",
        "    with torch.no_grad():  # No gradients needed for evaluation\n",
        "        for batch in test_loader:\n",
        "            x_batch, mask_batch = batch  # Unpack the tuple\n",
        "            x_batch = x_batch.to(device)          # Move input IDs to the device\n",
        "            mask_batch = mask_batch.to(device)    # Move attention masks to the device\n",
        "            logits = model(x_batch, mask=mask_batch)  # Include attention mask\n",
        "            preds = torch.argmax(logits, dim=-1)  # Get predictions\n",
        "            predictions.extend(preds.cpu().tolist())  # Convert tensor to list and extend\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68N5sa83T2zw",
        "outputId": "d04e4f7e-c893-4479-ced7-f6ef27c108f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to submission.csv\n"
          ]
        }
      ],
      "source": [
        "# Assuming `test_loader` is defined and contains the test data\n",
        "predictions = evaluate_model(model, test_loader)\n",
        "\n",
        "# Convert predictions to a DataFrame and save for Kaggle submission\n",
        "submission_df = pd.DataFrame({\n",
        "    \"SampleID\": data[\"SampleID\"],  # Replace with your test set's ID column\n",
        "    \"Category\": predictions  # Predictions returned by the function\n",
        "})\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Predictions saved to submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "fAzNGELiUFOb",
        "outputId": "034875bb-ac89-4d13-ae4e-5805a8f36938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10557, 2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"submission_df\",\n  \"rows\": 10557,\n  \"fields\": [\n    {\n      \"column\": \"SampleID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3047,\n        \"min\": 1,\n        \"max\": 10557,\n        \"num_unique_values\": 10557,\n        \"samples\": [\n          1951,\n          10004,\n          6399\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "submission_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-748f780b-707d-4273-a335-c5bfc7a5dc35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SampleID</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-748f780b-707d-4273-a335-c5bfc7a5dc35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-748f780b-707d-4273-a335-c5bfc7a5dc35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-748f780b-707d-4273-a335-c5bfc7a5dc35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d1b8208-1469-4631-9f31-772a063ef396\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d1b8208-1469-4631-9f31-772a063ef396')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d1b8208-1469-4631-9f31-772a063ef396 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   SampleID  Category\n",
              "0         1         3\n",
              "1         2         0\n",
              "2         3         1\n",
              "3         4         4\n",
              "4         5         3\n",
              "5         6         0\n",
              "6         7         3\n",
              "7         8         0\n",
              "8         9         2\n",
              "9        10         2"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(submission_df.shape)\n",
        "submission_df.head(10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}